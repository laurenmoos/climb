{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6fed3b",
   "metadata": {},
   "source": [
    "# RNN / Pytorch / Instruction Offset\n",
    "\n",
    "### Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c60860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class OPSTRING(Enum):\n",
    "    OR = '|'\n",
    "    AND = '&'\n",
    "    NOT = '~'\n",
    "    MOV = 'mov'\n",
    "    XOR = 'xor'\n",
    "    IDENTITY = 'identity'\n",
    "    \n",
    "op_string_to_ops = {OPSTRING.OR: np.bitwise_or, OPSTRING.AND: np.bitwise_and,\n",
    "                    OPSTRING.NOT: np.bitwise_not, OPSTRING.XOR: np.bitwise_xor,\n",
    "                    OPSTRING.MOV: lambda x: x, OPSTRING.IDENTITY: lambda x: x}\n",
    "\n",
    "ARITY_DICT = {OPSTRING.OR: 2, OPSTRING.AND: 2, OPSTRING.NOT: 1, OPSTRING.MOV: 1, OPSTRING.IDENTITY: 1, OPSTRING.XOR: 2}\n",
    "FUNCTION_SET = [\"&\", \"|\", \"mov\", \"~\", \"identity\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce43841",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840e92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "\n",
    "\n",
    "class Op:\n",
    "\n",
    "    def __init__(self, op_str, fx, arity):\n",
    "        self.op_str = op_str\n",
    "        self.fx = fx\n",
    "        self.arity = arity\n",
    "\n",
    "    @staticmethod\n",
    "    def from_string(op_str):\n",
    "        op_str = OPSTRING(op_str)\n",
    "        return Op(op_str, op_string_to_ops[op_str], ARITY_DICT[op_str])\n",
    "\n",
    "class Inst:\n",
    "\n",
    "    def __init__(self, src: int, dst: int, op: str):\n",
    "        self.src = src\n",
    "        self.dst = dst\n",
    "        self.op = Op.from_string(op)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_string(inst_str):\n",
    "        \"\"\"\n",
    "        :param inst_str: in polish notation\n",
    "        :return: Inst instance\n",
    "        \"\"\"\n",
    "        tokens = inst_str.split(\" \")\n",
    "        # Lucca uses Hungarian notation\n",
    "        return Inst(int(tokens[2]), int(tokens[1]), tokens[0])\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.op == other.op \\\n",
    "               and self.op.arity == other.arity \\\n",
    "               and self.dst == other.dst \\\n",
    "               and self.src == other.src\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        :return: string representation of instructions in polish notation\n",
    "        \"\"\"\n",
    "        pr_print = {\"OP:\": self.op.op_str, \"SRC\": self.src, \"DST\": self.dst}\n",
    "        return str(pr_print)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.op, self.src, self.dst))\n",
    "\n",
    "class Task:\n",
    "    \"\"\"\n",
    "    Initialized only once from configuration, task parameterizes search by fixing the machine architecture, as well\n",
    "    as problem specific characteristics such as max sequence length, function set etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, function_set: list, num_regs: int, num_data_regs:int, output_regs: list, dataset: str, constraints: list,\n",
    "                 sequence_length:int, arity:dict):\n",
    "\n",
    "        self.function_set = function_set\n",
    "        self.num_regs = num_regs\n",
    "        self.num_data_regs = num_data_regs\n",
    "        self.output_regs = list(output_regs)\n",
    "        self.dataset = dataset\n",
    "        self.constraints = constraints\n",
    "        self.instruction_shape = self.number_of_possible_insts()\n",
    "        self.inst_to_vec, self.vec_to_inst = self.index_mappings()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.arity = arity\n",
    "\n",
    "    def index_mappings(self):\n",
    "        \"\"\"\n",
    "        :return: mapping and reverse mapping between instructions and their one-hot encoded index\n",
    "        note: this is for a very simple one-hot embedding approach\n",
    "        \"\"\"\n",
    "        #TODO: this should be all regsiters times the number of executable regs - maybe minus introns\n",
    "        a = [range(self.num_regs), range(self.num_data_regs), self.function_set]\n",
    "        instructions = list(itertools.product(*a))\n",
    "\n",
    "        l, m = {}, {}\n",
    "        for idx, inst in enumerate(instructions):\n",
    "            instruction = Inst(inst[0], inst[1], inst[2])\n",
    "            l[instruction] = idx\n",
    "            m[idx] = instruction\n",
    "        return l, m\n",
    "\n",
    "    def number_of_possible_insts(self):\n",
    "        \"\"\"\n",
    "        :return: number of possible instructions given the machine architecture and the function set\n",
    "        \"\"\"\n",
    "        return self.num_regs * (self.num_regs + self.num_data_regs) * len( self.function_set)\n",
    "\n",
    "    # TODO: improve the instruction embedding\n",
    "    def inst_to_onehot(self, inst_offset: int):\n",
    "        \"\"\"\n",
    "        :return: naive one-hot encoded embedding of any possible instruction given the task\n",
    "        \"\"\"\n",
    "        one_hot = F.one_hot(torch.tensor(inst_offset), num_classes=self.instruction_shape)\n",
    "        one_hot = one_hot.type(torch.FloatTensor)\n",
    "        return torch.tensor(one_hot, dtype=torch.bool)\n",
    "\n",
    "    @staticmethod\n",
    "    def constraint(action):\n",
    "        \"\"\"\n",
    "        :return: is a given action (instruction) is an intron\n",
    "        this is in an in-situ constraint to produce programs with only meaningful instructions\n",
    "        for now: ones that do not contain instructions that are semantic introns\n",
    "        \"\"\"\n",
    "        return not semantic_intron(action)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9709ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_task():\n",
    "    return Task(\n",
    "        function_set=FUNCTION_SET,\n",
    "        num_regs=7,\n",
    "        num_data_regs=7,\n",
    "        output_regs= [6],\n",
    "        dataset=\"test_data/6-bit-parity.csv\",\n",
    "        constraints = [],\n",
    "        sequence_length=8,\n",
    "        arity=ARITY_DICT\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e4e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = test_task()\n",
    "\n",
    "sequence_length = 4\n",
    "steps_left = sequence_length\n",
    "instruction_offsets = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "#I think we can train with indices versus full sparse vectors \n",
    "for i in range(0, steps_left):\n",
    "    observation_shape = (sequence_length,)\n",
    "    observation_space = torch.zeros(observation_shape, dtype=torch.bool)\n",
    "\n",
    "    action_space = task.vec_to_inst\n",
    "    one_hot_encoded_action = instruction_offsets[steps_left - 1]\n",
    "    observation_space[sequence_length - steps_left] = one_hot_encoded_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b16e76",
   "metadata": {},
   "source": [
    "### Initialize the Networks\n",
    "\n",
    "There are a few characteristics of the input for this RNN. One, since we evaluate once per episode it is likely we will use some kind of padding for the candidate programs, i.e.\n",
    "\n",
    "INST, PAD, PAD, PAD, PAD\n",
    "INST, INST, PAD, PAD, PAD\n",
    "INST, INST, INST, PAD, PAD\n",
    "INST, INST, INST, INST, PAD\n",
    "INST, INST, INST, INST, INST\n",
    "\n",
    "for an episode, sequence length of 5\n",
    "\n",
    "However, as long as it is the case that the network is only fed a program at the end of the episode (along with the discounted reward) this might not be necessary.\n",
    "\n",
    "There are two interesting problems, one is regressing reward/value with the actor and critic networks fed the input of a sequence and outputting a reward. There is another toy problem where compilation can be treated as a multi-class classification problem (represented by the output binary vector) which could be perhaps used to learn an embedding. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8394a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "def create_rnn(vocab_size, embedding_dim, hidden_size, n_layers, output_size):\n",
    "    net_layers = []\n",
    "    net_layers.append(nn.Embedding(vocab_size, embedding_dim))\n",
    "    net_layers.append(nn.RNN(embedding_dim, hidden_size, n_layers, bidirectional=False))\n",
    "    return nn.Sequential(*net_layers)\n",
    "\n",
    "# class ActorCategoricalRNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers):\n",
    "#         super().__init__()      \n",
    "        \n",
    "#         #embedding layer\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "#         self.rnn = create_rnn(embedding_dim, hidden_dim, n_layers)\n",
    "        \n",
    "#         self.act = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, states):\n",
    "#         embedded = self.embedding(states)\n",
    "#         #embeddeed = [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "#         #sequences are fixed length so don't need any packing \n",
    "#         logits, _ = self.rnn(embedded)\n",
    "        \n",
    "#         pi = Categorical(logits=logits)\n",
    "#         actions = pi.sample()\n",
    "\n",
    "#         return pi, actions\n",
    "\n",
    "#vocab is the set of possible instructions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea538366",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = create_rnn(vocab_size = task.instruction_shape, embedding_dim = 24, hidden_size = 8, n_layers = 8, output_size = task.instruction_shape )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f4e06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "states = torch.zeros(size = (batch_size, sequence_length,), dtype=torch.int)\n",
    "states = states.to(torch.int64)\n",
    "print(states)\n",
    "\n",
    "outputs, hx = rnn.forward(states)\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d58005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c21d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
